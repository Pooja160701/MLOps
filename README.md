# ğŸš€ Hello World MLOps â€” End-to-End ML Pipeline with CI/CD

An end-to-end Machine Learning Operations (MLOps) project that demonstrates how to train, package, serve, and automate deployment of a machine learning model using modern DevOps practices.

This project trains a classification model on the Iris dataset, exposes it via a REST API, containerizes the service with Docker, and automates training using GitHub Actions CI.

---

## ğŸ“Œ Features

* âœ… Model training pipeline
* âœ… Model artifact generation
* âœ… REST API for inference (Flask)
* âœ… Command-line inference script
* âœ… Docker containerization
* âœ… Automated CI workflow (GitHub Actions)
* âœ… Health check endpoint
* âœ… Reproducible environment via requirements.txt

---

## ğŸ§  Problem Statement

Build a production-ready pipeline that demonstrates how machine learning models move from development to deployment in a reliable, automated manner.

---

## ğŸ—ï¸ Project Architecture

```text
Developer â†’ GitHub Push â†’ CI Pipeline â†’ Model Training â†’ Artifacts â†’ Deployment
```

### Components

* **Training Layer:** `train.py`
* **Inference Layer:** `app.py`, `run_model.py`
* **Artifacts:** Serialized model + metrics
* **Containerization:** Dockerfile
* **Automation:** GitHub Actions workflow

---

## ğŸ“‚ Project Structure

```text
hello-world-mlops/
â”‚
â”œâ”€â”€ .github/workflows/
â”‚   â””â”€â”€ ci.yml              # CI pipeline
â”‚
â”œâ”€â”€ artifacts/              # Generated model & metrics
â”‚   â”œâ”€â”€ model.pkl
â”‚   â””â”€â”€ metrics.json
â”‚
â”œâ”€â”€ app.py                  # Flask API server
â”œâ”€â”€ train.py                # Model training script
â”œâ”€â”€ run_model.py            # CLI inference script
â”œâ”€â”€ requirements.txt        # Dependencies
â”œâ”€â”€ Dockerfile              # Container config
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```

---

## âš™ï¸ Installation

### 1ï¸âƒ£ Clone Repository

```bash
git clone https://github.com/Pooja160701/MLOps.git
cd MLOps
```

---

### 2ï¸âƒ£ Create Virtual Environment (Recommended)

#### Windows (Git Bash)

```bash
python -m venv venv
source venv/Scripts/activate
```

#### macOS/Linux

```bash
python3 -m venv venv
source venv/bin/activate
```

---

### 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

---

## ğŸ§ª Train the Model

```bash
python train.py
```

This will:

* Train the classifier
* Save the model to `artifacts/model.pkl`
* Save evaluation metrics to `artifacts/metrics.json`

---

## ğŸ”® Run Inference (CLI)

```bash
python run_model.py --input "[5.1, 3.5, 1.4, 0.2]"
```

### Output Example

```json
{"prediction": [0]}
```

---

## ğŸŒ Run REST API Server

```bash
python app.py
```

Server runs at:

```
http://127.0.0.1:5001
```

---

## â¤ï¸ Health Check Endpoint

```bash
GET /health
```

Example:

```bash
curl http://127.0.0.1:5001/health
```

Response:

```json
{"status": "ok"}
```
![alt text](image.png)
---

## ğŸ”® Prediction Endpoint

```bash
POST /predict
```

### Example Request

```bash
curl -X POST http://127.0.0.1:5001/predict \
  -H "Content-Type: application/json" \
  -d '{"features":[5.1, 3.5, 1.4, 0.2]}'
```

### Response

```json
{"prediction": 0}
```
![alt text](image-1.png)
---

## ğŸ³ Docker Usage

### Build Image

```bash
docker build -t mlops-iris .
```

### Run Container

```bash
docker run -p 5001:5001 mlops-iris
```

---

## ğŸ” Continuous Integration (GitHub Actions)

The CI pipeline automatically:

1. Runs on push or pull request to `main`
2. Installs dependencies
3. Trains the model
4. Generates artifacts
5. Uploads artifacts for download

### Workflow File

```
.github/workflows/ci.yml
```

---

## ğŸ“¦ CI Artifacts

After each successful run, GitHub stores:

* Trained model (`model.pkl`)
* Metrics (`metrics.json`)

Accessible via:

ğŸ‘‰ GitHub â†’ Actions â†’ Workflow Run â†’ Artifacts
![alt text](image-2.png)
---

## ğŸ“Š Dataset

This project uses the classic **Iris dataset**, a multiclass classification problem predicting flower species based on sepal and petal measurements.

Classes:

* 0 â†’ Setosa
* 1 â†’ Versicolor
* 2 â†’ Virginica

---

## ğŸ› ï¸ Tech Stack

* Python
* Scikit-learn
* Flask
* NumPy
* Joblib
* Docker
* GitHub Actions (CI/CD)

---

## ğŸ” Reproducibility

Dependencies are pinned in `requirements.txt`, ensuring consistent builds across environments.

---

## ğŸš€ Future Improvements

* Model versioning (MLflow)
* Data versioning (DVC)
* Continuous deployment to cloud
* Monitoring & logging
* Kubernetes deployment
* API documentation (Swagger/OpenAPI)
* Performance benchmarking

---

## ğŸ‘©â€ğŸ’» Author

**Pooja**

---

## ğŸ“œ License

This project is for educational and demonstration purposes.

---